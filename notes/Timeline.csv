Date, meeting
05/09/23, First meeting about topic "Why is depth useful"
21/11/23, Second meeting discussing the dataset and possible experiments
29/11/23, Setting up the project for the first experiment regarding MNIST
-, Set up Segmentation network DFormer for experiments
-, Research what reasons are given for depth being useful
13/12/23, Meeting Sander
-, Discarding MNIST moving to Unity SynthDet dataset
09/01/24, Meeting
-, Converting the Unity SynthDet dataset to a format compatible with DFormer
-, Training DFormer on varied datasets: trying to find out when depth is useful
22/01/24, Midterm presentation + First Stage Evaluation
-, Setting up UNet with batch normalization for RGB comparison
-, Training UNet on varied datasets: trying to find out when depth is useful
01/02/24, Meeting Sander
-, Comparing the results of the two networks
10/02/24, Meeting: Discussing comparing DFormer with UNet - need SOTA RGB network as baseline
-, Discarding UNet: no baseline performance because it is crafted from scratch: not reliable
-, Comparing DFormer over different depths with same RGB: noise hurts depth but not much
-, Comparing DFormer RGB with RGB-D with D: surprisingly much information in depth
-, Training on "SOTA" pytorch-deeplab-xception with RGB to compare to DFormer RGB-Black
-, Results on pytorch-deeplab-xception: significantly lower accuracy: maybe DFormer pretrained weights interfere
19/02/24, Meeting Sander: Is deeplab suitable to compare since its a completely different architecture?
-, Re-training DFormer on SUNRGBD dataset without pretrained weights
-, Considerably lower results without pretrained weights: DFormer needs pretrained weights?
-, Setting up scripts to execute SynthDet experiments in one go: Unity -> create dataset -> run script
11/04/24, Student meeting presentation 1
29/04/24, Green Light Evaluation
06/06/24, Student meeting presentation 2
10/06/24, Thesis Defense
